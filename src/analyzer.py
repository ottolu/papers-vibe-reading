"""Gemini 3.0 Pro Vibe Reading â€” analyse papers via the Google GenAI SDK."""

from __future__ import annotations

import asyncio
import io
import json
import logging
import time
from datetime import date
from pathlib import Path
from typing import TYPE_CHECKING

from google import genai
from google.genai import types
import httpx

from . import config

if TYPE_CHECKING:
    from .fetcher import Paper

logger = logging.getLogger(__name__)

VIBE_READING_PROMPT = """\
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„ AI researcherï¼Œç²¾é€šå­¦æœ¯å†…å®¹è§£è¯»ä¸æ•°æ®å¯è§†åŒ–ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ä¸€ç¯‡å¤æ‚çš„å­¦æœ¯è®ºæ–‡ï¼Œè½¬åŒ–ä¸ºä¸€ä»½ç¬¦åˆèƒ½è®©è¯»è€…é«˜æ•ˆã€å¿«é€ŸæŒæ¡æ–‡ç« æ ¸å¿ƒå†…å®¹ã€åŸç†å’Œåˆ›æ–°ç‚¹çš„é˜…è¯»ææ–™ã€‚
è¯·å°†ä¸Šä¼ çš„æŒ‡å®šå­¦æœ¯è®ºæ–‡ï¼ŒæŒ‰ç…§è¦æ±‚ç”Ÿæˆä¸€ä»½èƒ½è®©è¯»è€…é«˜æ•ˆã€å¿«é€ŸæŒæ¡æ–‡ç« æ ¸å¿ƒå†…å®¹ã€åŸç†å’Œåˆ›æ–°ç‚¹çš„é˜…è¯»ææ–™ï¼Œå…¶ä¸­éœ€æ·±åº¦è§£æå¹¶é‡ç‚¹å±•ç¤ºè®ºæ–‡çš„
- **ç ”ç©¶åŠ¨æœº**ï¼šå‘ç°äº†ä»€ä¹ˆé—®é¢˜ï¼Œä¸ºä»€ä¹ˆéœ€è¦è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡ç ”ç©¶çš„ significance æ˜¯ä»€ä¹ˆ
- **æ•°å­¦è¡¨ç¤ºåŠå»ºæ¨¡**ï¼šä»ç¬¦å·/è¡¨ç¤ºåˆ°å…¬å¼ï¼Œä»¥åŠå…¬å¼æ¨å¯¼å’Œç®—æ³•æµç¨‹ï¼Œæ³¨æ„æ”¯æŒ latex çš„æ¸²æŸ“
- **å®éªŒæ–¹æ³•ä¸å®éªŒè®¾è®¡**ï¼šç³»ç»Ÿæ€§æ•´ç†å®éªŒç»†èŠ‚ï¼ˆæ¯”å¦‚æ¨¡å‹ã€æ•°æ®ã€è¶…å‚æ•°ã€promptç­‰ï¼‰ï¼Œå°½å¯èƒ½å‚è€ƒ appendixï¼Œè¾¾åˆ°å¯å¤ç°çš„ç¨‹åº¦ï¼›
- **å®éªŒç»“æœåŠæ ¸å¿ƒç»“è®º**ï¼šå¯¹æ¯”äº†é‚£äº›baselineï¼Œè¾¾åˆ°äº†ä»€ä¹ˆæ•ˆæœï¼Œæ­ç¤ºäº†ä»€ä¹ˆç»“è®ºå’Œinsights
- **ä½ çš„è¯„è®º**ï¼šä½œä¸ºä¸€ä¸ªçŠ€åˆ©çš„reviewerï¼Œæ•´ä½“é”è¯„ä¸‹è¿™ç¯‡å·¥ä½œï¼Œä¼˜åŠ¿ä¸ä¸è¶³ï¼Œä»¥åŠå¯èƒ½çš„æ”¹è¿›æ–¹å‘
- **æ€è€ƒé¢˜**: æå‡ºä¸‰ä¸ªåŸºäºè¿™ç¯‡æ–‡ç« çš„æ€è€ƒé—®é¢˜ï¼Œéš¾åº¦å±‚å±‚é€’è¿›ï¼Œè€ƒå¯Ÿè¯»è€…å¯¹è¿™ç¯‡æ–‡ç« çš„ç†è§£ã€‚
- **One More Thing**: ä½ ä¹Ÿå¯ä»¥è‡ªç”±å‘æŒ¥æœ¬æ–‡ä¸­å…¶ä»–ä½ è®¤ä¸ºé‡è¦ã€å¸Œæœ›åˆ†äº«ç»™æˆ‘çš„å†…å®¹
æ³¨æ„ï¼š
1. æ‰€æœ‰çš„ç¬¦å·åŠå…¬å¼ï¼Œéƒ½è¦èƒ½æ”¯æŒæ­£ç¡®è¿›è¡Œ latex æ¸²æŸ“ï¼ˆä¸åªæ˜¯å…¬å¼å—ï¼Œè¿˜åŒ…æ‹¬inlineçš„å…¬å¼ï¼Œæ³¨æ„**è¡Œå†…å…¬å¼ä¸è¦æ¢è¡Œ**ï¼‰ï¼›
2. é™¤å…¬å¼ä»¥åŠä¸€äº›æ ¸å¿ƒæœ¯è¯­å’ŒæŠ€æœ¯åè¯å¤–ï¼Œå°½å¯èƒ½ç”¨ä¸­æ–‡ã€‚
3. figure/table æ’å…¥æ—¶ï¼Œç”¨è®ºæ–‡ä¸­å…·ä½“çš„ figure/table æ¥è¡¨ç¤ºã€‚ç‰¹åˆ«çš„ï¼Œå¯¹äºå›¾ç‰‡ï¼Œå¦‚æœæ— æ³•ç›´æ¥æ”¾åˆ°ç½‘é¡µä¸­ï¼Œå°±ä½¿ç”¨å ä½ç¬¦è¡¨ç¤ºï¼Œæ–¹ä¾¿æ£€ç´¢ï¼›å¯¹äºè¡¨æ ¼ï¼Œå¦‚æœæ˜¯å…³é”®å®éªŒç›¸å…³è¡¨æ ¼ åˆ™æŒ‰ç…§latexæ ¼å¼è¿›è¡Œæ¸²æŸ“ï¼Œå°†è¡¨æ ¼å†…å…·ä½“å†…å®¹æ”¾åˆ°ç½‘é¡µä¸­ã€‚
4. è¦å°½å¯èƒ½åœ°äº‹æ— å·¨ç»†ï¼Œç›®æ ‡æ˜¯è¯»å®Œè¿™ä¸ªææ–™ï¼ŒåŸºæœ¬æŠŠæ¡äº†è®ºæ–‡90%çš„å†…å®¹äº†ï¼Œå¯ä»¥è¾¾åˆ°å¤ç°è®ºæ–‡çš„ç¨‹åº¦ã€‚

---

**æœ€åï¼Œè¯·åœ¨åˆ†ææ–‡æœ¬ç»“æŸåï¼Œè¿½åŠ ä¸€ä¸ª JSON å…ƒæ•°æ®å—ã€‚** è¯·ä½¿ç”¨å¦‚ä¸‹æ ¼å¼ï¼Œç”¨ ` ```json:metadata ``` ` å›´æ åŒ…è£¹ï¼š

```json:metadata
{
  "one_line_summary": "ä¸€å¥è¯æ€»ç»“ï¼ˆä¸­æ–‡ï¼Œ30å­—ä»¥å†…ï¼‰",
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3"],
  "difficulty": 3,
  "novelty": 4,
  "practicality": 4,
  "topics": ["ä¸»é¢˜1", "ä¸»é¢˜2"],
  "key_metrics": [
    {"name": "æŒ‡æ ‡å", "value": "æ•°å€¼", "context": "å¯¹æ¯”è¯´æ˜"}
  ],
  "mermaid_concept_map": "graph TD\\n    A[é—®é¢˜] --> B[æ–¹æ³•]\\n    B --> C[ç»“æœ]",
  "related_areas": ["ç›¸å…³é¢†åŸŸ1", "ç›¸å…³é¢†åŸŸ2"]
}
```

å­—æ®µè¯´æ˜ï¼š
- `one_line_summary`ï¼šä¸€å¥è¯æ¦‚æ‹¬è®ºæ–‡æ ¸å¿ƒè´¡çŒ®ï¼Œä¸­æ–‡ï¼Œä¸è¶…è¿‡30å­—
- `tags`ï¼š3-5ä¸ªå…³é”®è¯æ ‡ç­¾ï¼ˆè‹±æ–‡ï¼‰ï¼Œå¦‚ "LLM", "RL", "Efficiency", "Vision"
- `difficulty`ï¼šé˜…è¯»éš¾åº¦ 1-5ï¼ˆ1=å…¥é—¨ï¼Œ5=éå¸¸å›°éš¾ï¼‰
- `novelty`ï¼šåˆ›æ–°æ€§ 1-5ï¼ˆ1=å¢é‡æ”¹è¿›ï¼Œ5=å¼€åˆ›æ€§ï¼‰
- `practicality`ï¼šå®ç”¨æ€§ 1-5ï¼ˆ1=çº¯ç†è®ºï¼Œ5=å³åˆ»å¯ç”¨ï¼‰
- `topics`ï¼š2-4ä¸ªå…·ä½“ç ”ç©¶ä¸»é¢˜
- `key_metrics`ï¼šè®ºæ–‡ä¸­çš„å…³é”®å®éªŒæŒ‡æ ‡ï¼ˆ1-3ä¸ªï¼‰ï¼Œæ¯ä¸ªåŒ…å« name/value/context
- `mermaid_concept_map`ï¼šç”¨ Mermaid.js è¯­æ³•ç”»ä¸€ä¸ªç®€æ˜çš„æ¦‚å¿µå›¾/æµç¨‹å›¾ï¼Œå±•ç¤ºè®ºæ–‡æ ¸å¿ƒæ€è·¯ï¼ˆé—®é¢˜â†’æ–¹æ³•â†’ç»“æœï¼‰ï¼ŒèŠ‚ç‚¹æ–‡å­—ç”¨ä¸­æ–‡ï¼Œæ³¨æ„è½¬ä¹‰æ¢è¡Œä¸º \\n
- `related_areas`ï¼š2-3ä¸ªç›¸å…³ç ”ç©¶é¢†åŸŸ
"""

GEMINI_LOG_DIR = Path(config.OUTPUT_DIR) / "gemini_logs"

# PDFs larger than 20 MB must go through the File API (inline_data limit).
_INLINE_DATA_LIMIT = 20 * 1024 * 1024


def _build_client() -> genai.Client:
    """Create a Google GenAI client, routing through the configured proxy.

    Forces HTTP/1.1 when a proxy is configured â€” Clash proxies often fail
    the TLS/ALPN negotiation for HTTP/2, causing ``SSL: UNEXPECTED_EOF``.
    """
    proxy_url = config.get_proxy_url()
    if proxy_url:
        transport = httpx.HTTPTransport(
            proxy=proxy_url,
            http1=True,
            http2=False,
        )
        http_client = httpx.Client(transport=transport, timeout=300)
        return genai.Client(
            api_key=config.GEMINI_API_KEY,
            http_options=types.HttpOptions(httpxClient=http_client),
        )
    return genai.Client(api_key=config.GEMINI_API_KEY)


# ---------------------------------------------------------------------------
# Gemini call logging
# ---------------------------------------------------------------------------

def _log_dir(target_date: date) -> Path:
    """Return ``output/gemini_logs/YYYY-MM-DD/``."""
    d = GEMINI_LOG_DIR / target_date.isoformat()
    d.mkdir(parents=True, exist_ok=True)
    return d


def _save_request_log(
    arxiv_id: str,
    target_date: date,
    user_prompt: str,
    has_pdf: bool,
) -> None:
    """Persist the request we are about to send (everything except the binary PDF)."""
    safe = arxiv_id.replace("/", "_")
    path = _log_dir(target_date) / f"{safe}_request.json"
    payload = {
        "arxiv_id": arxiv_id,
        "model": config.GEMINI_MODEL,
        "contents_structure": {
            "role": "user",
            "parts": (
                ["Part(inline_data=PDF)", "Part(text=user_prompt)"]
                if has_pdf
                else ["Part(text=user_prompt)"]
            ),
        },
        "has_pdf_attachment": has_pdf,
        "user_prompt": user_prompt,
    }
    path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    logger.info("[%s] Request log â†’ %s", arxiv_id, path)


def _save_response_log(
    arxiv_id: str,
    target_date: date,
    response: types.GenerateContentResponse,
    analysis: str,
) -> None:
    """Persist the API response metadata + full analysis text."""
    safe = arxiv_id.replace("/", "_")
    path = _log_dir(target_date) / f"{safe}_response.json"

    # Extract usage metadata safely
    usage: dict = {}
    if response.usage_metadata:
        um = response.usage_metadata
        usage = {
            "prompt_tokens": getattr(um, "prompt_token_count", None),
            "candidates_tokens": getattr(um, "candidates_token_count", None),
            "total_tokens": getattr(um, "total_token_count", None),
        }

    # Extract finish reason
    finish_reason = None
    if response.candidates:
        fr = getattr(response.candidates[0], "finish_reason", None)
        finish_reason = str(fr) if fr else None

    payload = {
        "arxiv_id": arxiv_id,
        "model": config.GEMINI_MODEL,
        "finish_reason": finish_reason,
        "usage": usage,
        "analysis_length": len(analysis),
        "analysis": analysis,
    }
    path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    logger.info("[%s] Response log â†’ %s", arxiv_id, path)


def _save_error_log(
    arxiv_id: str,
    target_date: date,
    error: Exception,
) -> None:
    """Persist error information when the API call fails."""
    safe = arxiv_id.replace("/", "_")
    path = _log_dir(target_date) / f"{safe}_error.json"
    payload = {
        "arxiv_id": arxiv_id,
        "error_type": type(error).__name__,
        "error_message": str(error),
    }
    path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    logger.info("[%s] Error log â†’ %s", arxiv_id, path)


# ---------------------------------------------------------------------------
# Large-PDF upload via File API
# ---------------------------------------------------------------------------

def _upload_pdf_file(
    client: genai.Client,
    pdf_bytes: bytes,
    arxiv_id: str,
) -> types.Part:
    """Upload a large PDF via the Gemini File API and return a Part.

    The File API supports files up to 2 GB, compared to ~20 MB for
    inline_data.  This function blocks (synchronous SDK call) and is
    meant to be called via ``asyncio.to_thread()``.
    """
    uploaded = client.files.upload(
        file=io.BytesIO(pdf_bytes),
        config={"mime_type": "application/pdf", "display_name": f"{arxiv_id}.pdf"},
    )

    # Poll until processing completes (usually immediate for PDFs)
    while getattr(uploaded.state, "name", str(uploaded.state)) == "PROCESSING":
        time.sleep(2)
        uploaded = client.files.get(name=uploaded.name)

    state_name = getattr(uploaded.state, "name", str(uploaded.state))
    if state_name not in ("ACTIVE", "State.ACTIVE"):
        raise RuntimeError(f"File upload failed: state={state_name}")

    logger.info("[%s] PDF uploaded via File API: %s", arxiv_id, uploaded.name)
    return types.Part.from_uri(file_uri=uploaded.uri, mime_type=uploaded.mime_type)


# ---------------------------------------------------------------------------
# Core analysis
# ---------------------------------------------------------------------------

async def _generate(
    client: genai.Client,
    parts: list[types.Part],
    arxiv_id: str,
    target_date: date,
    user_text: str,
    has_pdf: bool,
) -> str:
    """Send parts to Gemini and return the analysis text.

    Raises on API errors so the caller can decide how to retry.
    """
    _save_request_log(arxiv_id, target_date, user_text, has_pdf)

    response = await asyncio.to_thread(
        client.models.generate_content,
        model=config.GEMINI_MODEL,
        contents=[types.Content(role="user", parts=parts)],
        config=types.GenerateContentConfig(max_output_tokens=16384),
    )
    analysis = response.text or ""
    logger.info("[%s] Analysis completed (%d chars)", arxiv_id, len(analysis))
    _save_response_log(arxiv_id, target_date, response, analysis)
    return analysis


async def analyze_paper(
    paper: "Paper",
    client: genai.Client,
    target_date: date,
) -> str:
    """Analyse a single paper with Gemini.

    Strategy:
      1. Try with PDF attached (inline_data for â‰¤20 MB, File API for larger).
      2. If the PDF fails (upload error or generation error), retry with
         just the title + abstract â€” still a full Gemini call, not a static
         template.
      3. Only fall back to ``_fallback_summary`` if even the abstract-only
         call fails.

    Returns
    -------
    str
        The model's Markdown-formatted analysis.
    """
    has_pdf = bool(paper.pdf_bytes)

    # -- Attempt 1: with PDF ------------------------------------------------
    if has_pdf:
        try:
            parts: list[types.Part] = []
            pdf_size = len(paper.pdf_bytes)

            if pdf_size > _INLINE_DATA_LIMIT:
                logger.info(
                    "[%s] PDF too large for inline_data (%d bytes, %.1f MB), "
                    "uploading via File API",
                    paper.arxiv_id, pdf_size, pdf_size / (1024 * 1024),
                )
                pdf_part = await asyncio.to_thread(
                    _upload_pdf_file, client, paper.pdf_bytes, paper.arxiv_id,
                )
                parts.append(pdf_part)
            else:
                parts.append(
                    types.Part.from_bytes(
                        data=paper.pdf_bytes, mime_type="application/pdf",
                    )
                )
                logger.info(
                    "[%s] Attaching PDF (%d bytes, %.1f KB) as inline_data",
                    paper.arxiv_id, pdf_size, pdf_size / 1024,
                )

            user_text = f"{VIBE_READING_PROMPT}"
            parts.append(types.Part.from_text(text=user_text))

            return await _generate(
                client, parts, paper.arxiv_id, target_date, user_text,
                has_pdf=True,
            )

        except Exception as exc:
            logger.warning(
                "[%s] PDF-based analysis failed (%s), retrying with abstract only",
                paper.arxiv_id, exc,
            )
            _save_error_log(paper.arxiv_id, target_date, exc)

    # -- Attempt 2: abstract only -------------------------------------------
    try:
        user_text = (
            f"è®ºæ–‡æ ‡é¢˜ï¼š{paper.title}\n\n"
            f"è®ºæ–‡æ‘˜è¦ï¼š\n{paper.summary}\n\n"
            f"{VIBE_READING_PROMPT}"
        )
        parts = [types.Part.from_text(text=user_text)]

        if has_pdf:
            logger.info("[%s] Retrying with abstract only", paper.arxiv_id)
        else:
            logger.warning(
                "[%s] No PDF available â€” using abstract", paper.arxiv_id,
            )

        return await _generate(
            client, parts, paper.arxiv_id, target_date, user_text,
            has_pdf=False,
        )

    except Exception as exc:
        logger.error("[%s] Abstract-only analysis also failed: %s", paper.arxiv_id, exc)
        _save_error_log(paper.arxiv_id, target_date, exc)
        return _fallback_summary(paper)


def _fallback_summary(paper: "Paper") -> str:
    """Generate a minimal summary when the AI call fails."""
    import json as _json

    metadata_block = _json.dumps(
        {
            "one_line_summary": paper.title[:30],
            "tags": ["AI", "ML"],
            "difficulty": 3,
            "novelty": 3,
            "practicality": 3,
            "topics": [],
            "key_metrics": [],
            "mermaid_concept_map": "",
            "related_areas": [],
        },
        ensure_ascii=False,
        indent=2,
    )
    return (
        f"## ğŸ“Œ ä¸€å¥è¯æ€»ç»“\n{paper.title}\n\n"
        f"## ğŸ”‘ æ ¸å¿ƒè´¡çŒ®\nï¼ˆAI åˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·å‚è€ƒåŸæ–‡æ‘˜è¦ï¼‰\n\n"
        f"## ğŸ› ï¸ æ–¹æ³•æ¦‚è¿°\n{paper.summary[:500]}\n\n"
        f"## ğŸ“Š å…³é”®ç»“æœ\nï¼ˆè¯·å‚è€ƒåŸæ–‡ï¼‰\n\n"
        f"## ğŸ’¡ ä¸ºä»€ä¹ˆå€¼å¾—å…³æ³¨\nè¯¥è®ºæ–‡åœ¨ HuggingFace ç¤¾åŒºè·å¾—äº† {paper.upvotes} ä¸ªèµã€‚\n\n"
        f"## ğŸ·ï¸ å…³é”®è¯æ ‡ç­¾\nAI, ML\n\n"
        f"```json:metadata\n{metadata_block}\n```"
    )


async def analyze_papers(
    papers: list["Paper"],
    target_date: date,
) -> list[str]:
    """Analyse multiple papers concurrently.

    Returns a list of analysis strings aligned with the input list.
    """
    client = _build_client()
    sem = asyncio.Semaphore(3)  # limit concurrency to avoid rate-limits

    async def _run(paper: "Paper") -> str:
        async with sem:
            return await analyze_paper(paper, client, target_date)

    results = await asyncio.gather(*[_run(p) for p in papers])
    return list(results)
